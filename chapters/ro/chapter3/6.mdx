<FrameworkSwitchCourse {fw} />

<!-- DISABLE-FRONTMATTER-SECTIONS

# Quiz pentru finalizarea capitolului[[end-of-chapter-quiz]]

<CourseFloatingBanner
    chapter={3}
    classNames="absolute z-10 right-0 top-0"
/>

Testează ce ai învățat în acest capitol!

### 1. Datasetul `emotion` conține mesaje de pe Twitter cu labeluri cu emoții. Căutați-l în [Hub](https://huggingface.co/datasets) și citiți card-ul datasetului. Care dintre acestea nu este una dintre emoțiile sale de bază?

<Question
	choices={[
		{
			text: "Fericire",
			explain: "Încercă din nou — emoția asta este prezentă în acest dataset!"
		},
		{
			text: "Iubire",
			explain: "Încercă din nou — emoția asta este prezentă în acest dataset!"
		},
		{
			text: "Confuzie",
			explain: "Corect! Confuzia nu este una dintre cele șase emoții de bază.",
            correct: true
		},
        {
			text: "Suprpiză",
			explain: "Supriză! Încearcă din nou!"
		}
	]}
/>

### 2. Căutați datasetul `ar_sarcasm` în [Hub](https://huggingface.co/datasets). Care este sarcina pe care o sprijină?

<Question
	choices={[
		{
			text: "Clasificarea sentimentului",
			explain: "Acesta este corect! Poți să știi grație etichetelor.",
            correct: true
		},
		{
			text: "Machine Translation",
			explain: "Acesta nu este corect — încercați din nou, în funcție de cardul datasetului <a href='https://huggingface.co/datasets/ar_sarcasm'>ar_sarcasm</a>!"
		},
		{
			text: "Reconstrucția entităților numite",
			explain: "Acesta nu este corect — încercați din nou, în funcție de cardul datasetului <a href='https://huggingface.co/datasets/ar_sarcasm'>ar_sarcasm</a>!"
		},
        {
			text: "Răspunsul întrebării",
			explain: "Nesatisfăcător — încercați din nou!"
		}
	]}
/>

### 3. Cum se așteaptă modelul BERT ca o pereche de propoziții să fie procesate?

<Question
	choices={[
		{
			text: "Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2",
			explain: "Este necesară un token special <code>[SEP]</code> pentru a separa cele două propoziții, dar nu e doar asta!"
		},
		{
			text: "[CLS] Tokens_of_sentence_1 Tokens_of_sentence_2",
			explain:"Este necesară un token special <code>[CLS]</code> pentru a separa cele două propoziții, dar nu e doar asta!
		},
		{
			text: "[CLS] Tokens_of_sentence_1 [SEP] Tokens_of_sentence_2 [SEP]",
			explain: "Acesta este corect!",
            correct: true
		},
        {
			text: "[CLS] Token-urile propoziției_1 [SEP] Token-urile propoziției_2",
			explain: "Este necesar un token special <code>[CLS]</code> la head, precum și un token special <code>[SEP]</code> pentru a separa cele două propoziții, dar nu e doar asta!"
		}
	]}
/>

{#if fw === 'pt'}
### 4. Care sunt beneficiile metodei `Dataset.map()`?

<Question
	choices={[
		{
			text: "Rezultatele funcției sunt cached, deci nu va lua timp dacă re-executăm codul.",
			explain: "Acest lucru este efectiv unul dintre beneficiile sale! Nu e doar asta...",
            correct: true
		},
		{
			text: "Se aplică multiprocessing pentru a merge mai rapid decât aplicarea funcției la fiecare element al datasetului.",
			explain: "Acest lucru este efectiv o caracteristică specială a acestei metode, dar nu e doar asta...",
            correct: true
		},
		{
			text: "Nu încarcă întregul datasetul în memorie și salvează rezultatele la fiecare element procesat.",
			explain: "Acest lucru este un avantaj al acestei metode. Există și altele...",
            correct: true
		},
	]}
/>

### 5. Ce înseamnă "dynamic padding"?

<Question
	alegeri={[  
		{
			text: "Dynamic padding este atunci când faci padding inputurilor pentru fiecare batch la lungimea maximă din întregul dataset.",
			explain: "Acest lucru implică paddingul, dar nu la lungimea maximă a întregului dataset."
		},
		{
			text: "Dynamic padding este atunci când faci padding inputurilor pentru fiecare batch, la lungimea maximă a propozițiilor din acel batch.",
			explain: "Este corect! Partea \"dynamic\" vine din faptul că dimensiunea fiecărui batch este determinată la momentul creării lui, iar toate batch-urile pot avea shape-uri diferite ca rezultat.",
            correct: true
		},
		{
			text: "Dynamic padding este atunci când faci padding inputurilor pentru ca fiecare propoziție să aibă același număr de tokenuri ca în precedentul dataset.",
			explain: "Este greșit, și nu are nici un sens să ne uităm la ordinea din dataset, deoarece îl amestecăm în timpul antrenării."
		},
	]}
/>

### 6. Care este scopul unei funcții collate?

<Question
	alegeri={[  
		{
			text: "Asigură că toate secvențele din dataset au aceeași lungime.",
			explain: "O funcție collate este implicată în gestionarea a câte unui batch, nu întregului dataset. De asemenea, vorbim despre funcții generice, nu <code>DataCollatorWithPadding</code> specific."
		},
		{
			text: "Adună toate sampleurile dintr-un batch.",
			explain: "Corect! Poți să dai ca argument o funcție collate în constructorul unui <code>DataLoader</code>. Am folosit funcția <code>DataCollatorWithPadding</code>, care face padding tuturor elementelor dintr-un batch, astfel încât ele să aibă aceeași lungime.",
            correct: true
		},
		{
			text: "Preprocesează întregul dataset.",
			explain: "Acest lucru ar fi o funcție de preprocesare, nu una collate."
		},
        {
			text: "Taie secvențele din dataset.",
			explain: "O funcție collate este implicată în gestionarea a câte un batch, nu întregului dataset. Dacă ești interesat în tăierea acestora, poți utiliza argumentul <code>truncate</code> al unui <code>tokenizer</code>."
		}
	]}
/>

### 7. Ce se întâmplă când inițializezi una dintre clasele `AutoModelForXxx` cu un pretrained language model (ca <code>bert-base-uncased</code>) care corespunde unei alte sarcini decât aceea pentru care a fost antrenat?

<Question
	alegeri={[  
		{
			text: "Nimic, dar se afișează un warning.",
			explain: "Se afișează un warning, dar asta nu este totul!"
		},
		{
			text: "Headul modelului preantrenat al modelului este înlăturat și înlocuit cu un head nou potrivit pentru sarcină.",
			explain: "Corect. De exemplu, atunci când am folosit <code>AutoModelForSequenceClassification</code> cu <code>bert-base-uncased</code>, am primit warningul la momentul inițializării modelului. Headul preantrenat nu este folosit pentru sarcina de clasificare a secvențelor, astfel încât el este înlăturat și înlocuit cu un head nou, cu weights aleatorii.",
            correct: true
		},
		{
			text: "Headul modelului preantrenat este înlăturat.",
			explain: "Trebuie să se întâmple încă ceva. Încearcă din nou!"
		},
        {
			text: "Nimic, deoarece modelul poate avea fine-tuning pentru o sarcina diferită.",
			explain: "Headul preantrenat al modelului nu a fost antrenat să rezolve această sarcină, astfel încât el trebuie înlăturat."
		}
	]}
/>

### 8. Care este scopul la `TrainingArguments`?

<Question
	alegeri={[  
		{
			text: "Conține toți hyperparametrii utilizați pentru antrenare și evaluare cu <code>Trainer</code>.",
			explain: "Corect!",
            correct: true
		},
		{
			text: "Specifică dimensiunea modelului.",
			explain: "Dimensiunea modelului este definită de configurația modelului, nu clasa <code>TrainingArguments</code>. "
		},
		{
			text: "Conține doar hyperparametrii utilizați pentru evaluare.",
			explain: "În exemplul nostru, am specificat unde se va salva modelul și toate checkpoint-urile. Încearcă din nou!"
		},
        {
			text: "Conține doar hyperparametrii utilizați pentru antrenare.",
			explain: "În exemplul nostru, am folosit un <code>evaluation_strategy</code>, astfel încât acest lucru afectează și evaluarea. Încearcă din nou!"
		}
	]}
/>

### 9. De ce ar trebui să folosim biblioteca 🤗 Accelerate?

<Question
	alegeri={[  
		{
			text: "Ofereă acces la modele mai rapide.",
			explain: "Nu, biblioteca 🤗 Accelerate nu oferă nici un model."
		},
		{
			text: "Oferă un API de nivel înalt astfel încât să nu trebuiască să implementăm singuri un training loop.",
			explain: "Acest lucru este ceea ce am făcut cu <code>Trainer</code>, nu biblioteca 🤗 Accelerate. Încearcă din nou!"
		},
		{
			text: "Face ca loopurile de antrenare să funcționeze pe distributed strategies.",
			explain: "Corect! Cu 🤗 Accelerate, loopurile de antrenare vor funcționa pentru multiple GPU-uri și TPU-uri.",
            correct: true
		},
        {
			text: "Oferă mai multe funcții de optimizare.",
			explain: "Nu, biblioteca 🤗 Accelerate nu oferă nici o funcțiune de optimizare."
		}
	]}
/>

{:else}
### 4. Ce se întâmplă când inițializezi una dintre clasele `TFAutoModelForXxx` cu un pretrained language model (ca <code>bert-base-uncased</code>) care corespunde unei alte sarcini decât aceea pentru care a fost antrenat?

<Question
	alegeri={[  
		{
			text: "Nimic, dar se afișează un warning.",
			explain: "Se afișează un warning, dar asta nu este totul!"
		},
		{
			text: "Headul preantrenat al modelului este înlăturat și înlocuit cu un head nou potrivit pentru sarcină.",
			explain: "Corect. De exemplu, atunci când am folosit <code>TFAutoModelForSequenceClassification</code> cu <code>bert-base-uncased</code>, am primit warningul la momentul inițializării modelului. Headul preantrenat nu este folosit pentru sarcina de clasificare a secvențelor, astfel încât el este înlăturat și înlocuit cu un head nou, cu weights aleatorii.",
            correct: true
		},
		{
			text: "Headul preantrenat al modelului este înlăturat.",
			explain: "Trebuie să se întâmple ceva mai mult. Încercă din nou!"
		},
        {
			text: "Nimic, deoarece modelul poate fi reantrenat pentru o sarcina diferită.",
			explain: "Headul prentrenat al modelului nu a fost antrenat să rezolve această sarcină, astfel încât el trebuie înlăturat."
		}
	]}
/>

### 5. Modelele TensorFlow din `transformers` sunt deja modele Keras. Ce beneficiu oferă acest lucru?

<Question
	alegeri={[  
		{
			text: "Modelele funcționează pe un TPU direct.",
			explain: "Ești aproape, dar sunt necesare mici schimbări. De exemplu, trebuie să rulezi totul într-un <code>TPUStrategy</code> scop, inclusiv inițializarea modelului."
		},
		{
			text: "Poți folosi metode existente precum <code>compile()</code>, <code>fit()</code>, și <code>predict()</code>.",
			explain: "Corect! Odată ce ai datele, antrenarea pe acestea necesită foarte puțin lucru.",
            correct: true
		},
		{
			text: "Poți învăța și Keras precum și Transformers.",
			explain: "Corect, dar căutăm altceva. :)",
			correct: true
		},
        {
			text: "Poți calcula ușor metrice legate de dataset.",
			explain: "Keras ne ajută cu antrenarea și evaluarea modelului, dar nu calculează metrice legate de dataset."
		}
	]}
/>

### 6. Cum poți defini o metrică personalizată?

<Question
	alegeri={[  
		{
			text: "Prin subclassing pe <code>tf.keras.metrics.Metric</code>.",
			explain: "Excelent!",
			correct: true
		},
		{
			text: "Folosind API-ul Keras.",
			explain: "Încercă din nou!"
		},
		{
			text: "Prin intermediul callable cu semnatura <code>metric_fn(y_true, y_pred)</code>.",
			explain: "Corect!",
			correct: true
		},
        {
			text: "Prin căutarea pe Google.",
			explain: "Acest lucru nu este răspunsul pe care îl căutăm, dar ar trebui să te ajute să-l găsești.",
            correct: true
		}
	]}
/>

{/if}