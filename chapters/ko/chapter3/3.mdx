<FrameworkSwitchCourse {fw} />

# Trainer API로 모델 미세 조정하기[[fine-tuning-a-model-with-the-trainer-api]]

<CourseFloatingBanner chapter={3}
  classNames="absolute z-10 right-0 top-0"
  notebooks={[
    {label: "Google Colab", value: "https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
    {label: "Aws Studio", value: "https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter3/section3.ipynb"},
]} />

<Youtube id="nvBXf7s7vTI"/>

🤗 Transformers는 `Trainer` 클래스를 제공하여 최신 모범 사례를 사용해 제공하는 사전 학습된 모델을 데이터셋에 미세 조정할 수 있도록 도와줍니다. 이전 섹션에서 모든 데이터 전처리 작업을 완료했다면, `Trainer`를 정의하는 데 몇 단계만 남았습니다. 가장 어려운 부분은 `Trainer.train()`을 실행할 환경을 준비하는 것일 수 있습니다. CPU에서는 매우 느리게 실행되기 때문입니다. GPU가 설정되어 있지 않다면, [Google Colab](https://colab.research.google.com/)에서 무료 GPU 또는 TPU에 액세스할 수 있습니다.

<Tip>

📚 **훈련 리소스**: 훈련을 시작하기 전에 포괄적인 [🤗 Transformers 훈련 가이드](https://huggingface.co/docs/transformers/main/en/training)를 숙지하고 [미세 조정 쿡북](https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu)의 실용적인 예제를 살펴보세요.

</Tip>

아래 코드 예제는 이미 이전 섹션의 예제를 실행했다고 가정합니다. 필요한 것을 요약한 간단한 요약은 다음과 같습니다:

```py
from datasets import load_dataset
from transformers import AutoTokenizer, DataCollatorWithPadding

raw_datasets = load_dataset("glue", "mrpc")
checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)


def tokenize_function(example):
    return tokenizer(example["sentence1"], example["sentence2"], truncation=True)


tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)
data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
```

### 훈련[[training]]

`Trainer`를 정의하기 전 첫 번째 단계는 `Trainer`가 훈련 및 평가에 사용할 모든 하이퍼파라미터를 포함하는 `TrainingArguments` 클래스를 정의하는 것입니다. 제공해야 하는 유일한 인수는 훈련된 모델이 저장될 디렉터리와 그 과정에서 생성되는 체크포인트입니다. 나머지는 기본값으로 둘 수 있으며, 이는 기본 미세 조정에서 꽤 잘 작동합니다.

```py
from transformers import TrainingArguments

training_args = TrainingArguments("test-trainer")
```

훈련 중에 모델을 Hub에 자동으로 업로드하려면 `TrainingArguments`에서 `push_to_hub=True`를 전달하세요. 이에 대해서는 [Chapter 4](/course/chapter4/3)에서 자세히 알아보겠습니다.

<Tip>

🚀 **고급 구성**: 사용 가능한 모든 훈련 인수와 최적화 전략에 대한 자세한 정보는 [TrainingArguments 문서](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments)와 [훈련 구성 쿡북](https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu)을 확인하세요.

</Tip>

두 번째 단계는 모델을 정의하는 것입니다. [이전 챕터](/course/chapter2)에서와 같이 두 개의 라벨과 함께 `AutoModelForSequenceClassification` 클래스를 사용하겠습니다:

```py
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)
```

[Chapter 2](/course/chapter2)와 달리 이 사전 학습된 모델을 인스턴스화한 후 경고가 나타나는 것을 확인할 수 있습니다. 이는 BERT가 문장 쌍 분류에 대해 사전 학습되지 않았기 때문에 사전 학습된 모델의 헤드가 제거되고 시퀀스 분류에 적합한 새로운 헤드가 대신 추가되었기 때문입니다. 경고는 일부 가중치가 사용되지 않았으며 (제거된 사전 학습 헤드에 해당하는 가중치) 일부 다른 가중치가 무작위로 초기화되었음을 나타냅니다 (새로운 헤드의 가중치). 모델을 훈련하도록 권장하며 이는 정확히 우리가 지금 하려는 것입니다.

모델이 있으면 지금까지 구성한 모든 객체(`model`, `training_args`, 훈련 및 검증 데이터셋, `data_collator`, `processing_class`)를 전달하여 `Trainer`를 정의할 수 있습니다. `processing_class` 매개변수는 처리에 사용할 토크나이저를 Trainer에 알려주는 새로운 추가 사항입니다:

```py
from transformers import Trainer

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    processing_class=tokenizer,
)
```

토크나이저를 `processing_class`로 전달하면 `Trainer`에서 사용하는 기본 `data_collator`가 `DataCollatorWithPadding`이 됩니다. 이 경우 `data_collator=data_collator` 줄을 생략할 수 있지만, 처리 파이프라인의 이 중요한 부분을 보여주기 위해 여기에 포함했습니다.

<Tip>

📖 **더 자세히 알아보기**: Trainer 클래스와 그 매개변수에 대한 포괄적인 세부 정보는 [Trainer API 문서](https://huggingface.co/docs/transformers/main/en/main_classes/trainer)를 방문하고 [훈련 쿡북 레시피](https://huggingface.co/learn/cookbook/en/fine_tuning_code_llm_on_single_gpu)에서 고급 사용 패턴을 살펴보세요.

</Tip>

데이터셋에서 모델을 파인튜닝하려면 `Trainer`의 `train()` 메서드를 호출하기만 하면 됩니다:

```py
trainer.train()
```

이렇게 하면 파인튜닝이 시작되고 (GPU에서 몇 분 정도 걸림) 500 스텝마다 훈련 손실을 보고합니다. 하지만 모델이 얼마나 잘 (또는 나쁘게) 수행되고 있는지는 알려주지 않습니다. 그 이유는 다음과 같습니다:

1. `TrainingArguments`에서 `eval_strategy`를 `"steps"` (매 `eval_steps`마다 평가) 또는 `"epoch"` (각 에포크 종료 시 평가)로 설정하여 훈련 중에 평가하도록 `Trainer`에 알리지 않았습니다.
2. 해당 평가 중에 메트릭을 계산하기 위한 `compute_metrics()` 함수를 `Trainer`에 제공하지 않았습니다 (그렇지 않으면 평가에서 손실만 출력되는데, 이는 직관적이지 않은 숫자입니다).


### 평가[[evaluation]]

유용한 `compute_metrics()` 함수를 빌드하고 다음 번 훈련에서 사용하는 방법을 살펴보겠습니다. 이 함수는 `EvalPrediction` 객체(`predictions` 필드와 `label_ids` 필드가 있는 명명된 튜플)를 받아야 하며 문자열을 플로트에 매핑하는 딕셔너리를 반환합니다 (문자열은 반환되는 메트릭의 이름이고 플로트는 그 값입니다). 모델에서 일부 예측을 얻으려면 `Trainer.predict()` 명령을 사용할 수 있습니다:

```py
predictions = trainer.predict(tokenized_datasets["validation"])
print(predictions.predictions.shape, predictions.label_ids.shape)
```

```python out
(408, 2) (408,)
```

`predict()` 메서드의 출력은 `predictions`, `label_ids`, `metrics` 세 개의 필드가 있는 또 다른 명명된 튜플입니다. `metrics` 필드는 전달된 데이터셋의 손실과 일부 시간 메트릭 (예측하는 데 걸린 시간, 총 시간 및 평균 시간)만 포함합니다. `compute_metrics()` 함수를 완료하고 `Trainer`에 전달하면 해당 필드에는 `compute_metrics()`에서 반환된 메트릭도 포함됩니다.

보시다시피 `predictions`는 408 x 2 모양의 2차원 배열입니다 (408은 사용한 데이터셋의 요소 수). 이는 `predict()`에 전달한 데이터셋의 각 요소에 대한 로짓입니다 ([이전 챕터](/course/chapter2)에서 보았듯이 모든 Transformer 모델은 로짓을 반환합니다). 라벨과 비교할 수 있는 예측으로 변환하려면 두 번째 축에서 최대값의 인덱스를 가져와야 합니다:

```py
import numpy as np

preds = np.argmax(predictions.predictions, axis=-1)
```

이제 이 `preds`를 라벨과 비교할 수 있습니다. `compute_metric()` 함수를 빌드하기 위해 🤗 [Evaluate](https://github.com/huggingface/evaluate/) 라이브러리의 메트릭을 활용하겠습니다. 데이터셋을 로드한 것처럼 쉽게 MRPC 데이터셋과 연관된 메트릭을 로드할 수 있습니다. 이번에는 `evaluate.load()` 함수를 사용합니다. 반환된 객체에는 메트릭 계산에 사용할 수 있는 `compute()` 메서드가 있습니다:

```py
import evaluate

metric = evaluate.load("glue", "mrpc")
metric.compute(predictions=preds, references=predictions.label_ids)
```

```python out
{'accuracy': 0.8578431372549019, 'f1': 0.8996539792387542}
```

<Tip>

다양한 평가 메트릭과 전략에 대해 [🤗 Evaluate 문서](https://huggingface.co/docs/evaluate/)에서 알아보세요.

</Tip>

모델 헤드의 무작위 초기화가 달성한 메트릭을 변경할 수 있으므로 정확한 결과는 달라질 수 있습니다. 여기서 모델이 검증 세트에서 85.78%의 정확도와 89.97의 F1 점수를 가지고 있음을 확인할 수 있습니다. 이는 GLUE 벤치마크의 MRPC 데이터셋에서 결과를 평가하는 데 사용되는 두 가지 메트릭입니다. [BERT 논문](https://arxiv.org/pdf/1810.04805.pdf)의 표에는 기본 모델에 대해 88.9의 F1 점수가 보고되었습니다. 그것은 `uncased` 모델이었지만 현재 `cased` 모델을 사용하고 있어 더 나은 결과를 설명합니다.

모든 것을 함께 래핑하면 `compute_metrics()` 함수를 얻습니다:

```py
def compute_metrics(eval_preds):
    metric = evaluate.load("glue", "mrpc")
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)
```

그리고 각 에포크 종료 시 메트릭을 보고하는 데 사용되는 것을 보려면 이 `compute_metrics()` 함수로 새로운 `Trainer`를 정의하는 방법은 다음과 같습니다:

```py
training_args = TrainingArguments("test-trainer", eval_strategy="epoch")
model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)

trainer = Trainer(
    model,
    training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["validation"],
    data_collator=data_collator,
    processing_class=tokenizer,
    compute_metrics=compute_metrics,
)
```

`eval_strategy`가 `"epoch"`로 설정된 새로운 `TrainingArguments`와 새로운 모델을 만든다는 점에 주목하세요. 그렇지 않으면 이미 훈련한 모델의 훈련을 계속하는 것입니다. 새로운 훈련 실행을 시작하려면 다음을 실행합니다:

```py
trainer.train()
```

이번에는 훈련 손실 외에 각 에포크 종료 시 검증 손실과 메트릭을 보고합니다. 다시 말하지만, 모델의 무작위 헤드 초기화로 인해 달성하는 정확한 정확도/F1 점수는 우리가 발견한 것과 약간 다를 수 있지만 같은 수준이어야 합니다.

### 고급 훈련 기능[[advanced-training-features]]

`Trainer`는 최신 딥러닝 모범 사례를 접근 가능하게 만드는 많은 내장 기능을 제공합니다:

**혼합 정밀도 훈련**: 더 빠른 훈련과 메모리 사용량 감소를 위해 훈련 인수에서 `fp16=True`를 사용하세요:

```py
training_args = TrainingArguments(
    "test-trainer",
    eval_strategy="epoch",
    fp16=True,  # 혼합 정밀도 활성화
)
```

**그래디언트 누적**: GPU 메모리가 제한될 때 효과적인 더 큰 배치 크기를 위해:

```py
training_args = TrainingArguments(
    "test-trainer",
    eval_strategy="epoch",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,  # 효과적인 배치 크기 = 4 * 4 = 16
)
```

**학습률 스케줄링**: Trainer는 기본적으로 선형 감소를 사용하지만 이를 사용자 정의할 수 있습니다:

```py
training_args = TrainingArguments(
    "test-trainer",
    eval_strategy="epoch",
    learning_rate=2e-5,
    lr_scheduler_type="cosine",  # 다른 스케줄러 시도
)
```

<Tip>

🎯 **성능 최적화**: 분산 훈련, 메모리 최적화, 하드웨어별 최적화를 포함한 고급 훈련 기술에 대해서는 [🤗 Transformers 성능 가이드](https://huggingface.co/docs/transformers/main/en/performance)를 살펴보세요.

</Tip>

`Trainer`는 여러 GPU 또는 TPU에서 즉시 작동하며 분산 훈련을 위한 많은 옵션을 제공합니다. 지원하는 모든 것에 대해서는 Chapter 10에서 다루겠습니다.

이것으로 `Trainer` API를 사용한 파인튜닝에 대한 소개를 마칩니다. 가장 일반적인 NLP 작업에 대해 이를 수행하는 예제는 [Chapter 7](/course/chapter7)에서 제공되지만, 지금은 순수 PyTorch 훈련 루프로 동일한 작업을 수행하는 방법을 살펴보겠습니다.

<Tip>

📝 **더 많은 예제**: [🤗 Transformers 노트북](https://huggingface.co/docs/transformers/main/en/notebooks)의 포괄적인 컬렉션을 확인하세요.

</Tip>

## 섹션 퀴즈[[section-quiz]]

Trainer API와 파인튜닝 개념에 대한 이해를 테스트해보세요:

### 1. <code>processing_class</code> 매개변수의 목적은 무엇인가요?

<Question
	choices={[
		{
			text: "사용할 모델 아키텍처를 지정합니다.",
			explain: "모델 아키텍처는 모델을 로드할 때 지정되며, Trainer에서 지정하지 않습니다."
		},
		{
			text: "데이터 처리에 사용할 토크나이저를 Trainer에 알려줍니다.",
			explain: "processing_class 매개변수는 사용할 토크나이저를 Trainer가 알 수 있도록 도와주는 최신 추가 사항입니다.",
            correct: true
		},
		{
			text: "훈련을 위한 배치 크기를 결정합니다.",
			explain: "배치 크기는 processing_class가 아닌 TrainingArguments에서 설정됩니다."
		},
        {
			text: "평가 빈도를 제어합니다.",
			explain: "평가 빈도는 TrainingArguments의 eval_strategy로 제어됩니다."
		}
	]}
/>

### 2. 훈련 중 평가가 얼마나 자주 발생하는지 제어하는 TrainingArguments 매개변수는 무엇인가요?

<Question
	choices={[
		{
			text: "eval_frequency",
			explain: "TrainingArguments에는 eval_frequency 매개변수가 없습니다."
		},
		{
			text: "eval_strategy",
			explain: "eval_strategy는 평가 타이밍을 제어하기 위해 'epoch', 'steps', 또는 'no'로 설정할 수 있습니다.",
            correct: true
		},
		{
			text: "evaluation_steps",
			explain: "eval_steps는 평가 사이의 단계 수를 설정하지만, eval_strategy가 평가 발생 여부/시기를 결정합니다."
		},
        {
			text: "do_eval",
			explain: "최신 TrainingArguments에는 do_eval 매개변수가 없습니다."
		}
	]}
/>

### 3. TrainingArguments에서 <code>fp16=True</code>는 무엇을 활성화하나요?

<Question
	choices={[
		{
			text: "더 빠른 훈련을 위한 16비트 정수 정밀도",
			explain: "fp16은 정수 정밀도가 아닌 부동소수점 정밀도를 의미합니다."
		},
		{
			text: "더 빠른 훈련과 메모리 사용량 감소를 위한 16비트 부동소수점 수를 사용한 혼합 정밀도 훈련",
			explain: "혼합 정밀도 훈련은 순전파에는 16비트 플로트를, 그래디언트에는 32비트를 사용하여 속도를 향상시키고 메모리 사용량을 줄입니다.",
            correct: true
		},
		{
			text: "정확히 16 에포크 동안 훈련",
			explain: "fp16은 에포크 수와 관련이 없습니다."
		},
        {
			text: "분산 훈련을 위한 16개 GPU 사용",
			explain: "GPU 수는 fp16 매개변수로 제어되지 않습니다."
		}
	]}
/>

### 4. Trainer에서 <code>compute_metrics</code> 함수의 역할은 무엇인가요?

<Question
	choices={[
		{
			text: "훈련 중 손실을 계산합니다.",
			explain: "손실 계산은 compute_metrics가 아닌 모델에서 자동으로 처리됩니다."
		},
		{
			text: "로짓을 예측으로 변환하고 정확도 및 F1과 같은 평가 메트릭을 계산합니다.",
			explain: "compute_metrics는 예측과 라벨을 받아서 평가를 위한 메트릭을 반환합니다.",
            correct: true
		},
		{
			text: "사용할 옵티마이저를 결정합니다.",
			explain: "옵티마이저 선택은 compute_metrics로 처리되지 않습니다."
		},
        {
			text: "훈련 데이터를 전처리합니다.",
			explain: "데이터 전처리는 훈련 전에 수행되며, 평가 중 compute_metrics로 수행되지 않습니다."
		}
	]}
/>

### 5. Trainer에 <code>eval_dataset</code>을 제공하지 않으면 어떻게 되나요?

<Question
	choices={[
		{
			text: "훈련이 오류와 함께 실패합니다.",
			explain: "eval_dataset 없이도 훈련을 진행할 수 있지만, 평가 메트릭은 얻을 수 없습니다."
		},
		{
			text: "Trainer가 자동으로 훈련 데이터를 평가용으로 분할합니다.",
			explain: "Trainer는 자동으로 검증 분할을 생성하지 않습니다."
		},
		{
			text: "훈련 중 평가 메트릭을 얻을 수 없지만 훈련은 여전히 작동합니다.",
			explain: "평가는 선택사항입니다 - 평가 없이도 훈련할 수 있지만 검증 메트릭은 볼 수 없습니다.",
            correct: true
		},
        {
			text: "모델이 평가를 위해 훈련 데이터를 사용합니다.",
			explain: "Trainer는 자동으로 평가를 위해 훈련 데이터를 사용하지 않습니다 - 단순히 평가하지 않습니다."
		}
	]}
/>

### 6. 그래디언트 누적이란 무엇이며 어떻게 활성화하나요?

<Question
	choices={[
		{
			text: "그래디언트를 디스크에 저장하는 것으로, save_gradients=True로 활성화됩니다.",
			explain: "그래디언트 누적은 그래디언트를 디스크에 저장하는 것과 관련이 없습니다."
		},
		{
			text: "업데이트 전에 여러 배치에 걸쳐 그래디언트를 누적하는 것으로, gradient_accumulation_steps로 활성화됩니다.",
			explain: "이를 통해 여러 순전파에 걸쳐 그래디언트를 누적하여 더 큰 배치 크기를 시뮬레이션할 수 있습니다.",
            correct: true
		},
		{
			text: "그래디언트 계산을 가속화하는 것으로, fp16과 함께 자동으로 활성화됩니다.",
			explain: "fp16이 훈련을 가속화할 수 있지만, 그래디언트 누적은 별도의 기술입니다."
		},
        {
			text: "그래디언트 오버플로우를 방지하는 것으로, gradient_clipping=True로 활성화됩니다.",
			explain: "이는 그래디언트 누적이 아닌 그래디언트 클리핑을 설명합니다."
		}
	]}
/>

<Tip>

💡 **핵심 요점:**
- `Trainer` API는 대부분의 훈련 복잡성을 처리하는 고수준 인터페이스를 제공합니다
- 적절한 데이터 처리를 위해 `processing_class`를 사용하여 토크나이저를 지정하세요
- `TrainingArguments`는 학습률, 배치 크기, 평가 전략, 최적화 등 훈련의 모든 측면을 제어합니다
- `compute_metrics`는 단순한 훈련 손실 외에 사용자 정의 평가 메트릭을 활성화합니다
- 혼합 정밀도(`fp16=True`)와 그래디언트 누적과 같은 최신 기능은 훈련 효율성을 크게 향상시킬 수 있습니다

</Tip>

